{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4efc2fde-43f3-4659-88ec-524310a1cb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Predictive Model Folder: c:\\Users\\ashly\\OneDrive\\Documents\\Education Material\\ResearchProject\\MaternalHealthResearch\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sdv\n",
    "import os\n",
    "\n",
    "new_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "os.chdir(new_dir)\n",
    "\n",
    "print('In Predictive Model Folder:', os.getcwd())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f773b",
   "metadata": {},
   "source": [
    "Phase 1 - Data Preprocessing \n",
    "1. Create Combination of Data for HeartRate to detect activity imbalances\n",
    "2. Create ManualInput Dataset \n",
    "3. Clean all datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30eb7ac",
   "metadata": {},
   "source": [
    "Step 1: Create the HeartRate and METS merged dataset, filter null values and reduce the memory usage first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a32175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDataset(df):\n",
    "    print('Filter Dataset')\n",
    "\n",
    "    # view details of the dataset\n",
    "    print(df.head())\n",
    "    print('Column Names:',df.dtypes)\n",
    "\n",
    "    # print null values in the dataframe\n",
    "    print('The sum of null values are:', df.isnull().sum())\n",
    "    \n",
    "    \n",
    "    # drop rows with null values\n",
    "    print('Count of cells BEFORE dropping null:', df.size,'\\n')\n",
    "    df = df.dropna() \n",
    "    print('Count of cells AFTER dropping null:', df.size, '\\n')\n",
    "    print('------------------------------------------------------------------')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed48b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDateTime(df):\n",
    "    # datetime split\n",
    "    split_datetime = df['timestamp'].str.split(' ', expand=True)\n",
    "\n",
    "    # Assign the date and time components to new columns\n",
    "    df['date'] = split_datetime[0]\n",
    "    df['time'] = split_datetime[1]\n",
    "\n",
    "    df.drop(columns=['timestamp'], inplace=True)\n",
    "    df[:3]\n",
    "    print('------------------------------------------------------------------')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "227be2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceMemoryUsage(df, verbose=True):\n",
    "    print('Reduce Memory')\n",
    "    \n",
    "    numerics = {\n",
    "        np.int8: (np.iinfo(np.int8).min,np.iinfo(np.int8).max),\n",
    "        np.int16: (np.iinfo(np.int16).min,np.iinfo(np.int16).max), \n",
    "        np.int32: (np.iinfo(np.int32).min,np.iinfo(np.int32).max), \n",
    "        np.int64: (np.iinfo(np.int64).min,np.iinfo(np.int64).max), \n",
    "        np.float16: (np.finfo(np.float16).min,np.finfo(np.float16).max), \n",
    "        np.float32: (np.finfo(np.float32).min,np.finfo(np.float32).max), \n",
    "        np.float64: (np.finfo(np.float64).min,np.finfo(np.float64).max)\n",
    "        }\n",
    "    types = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_memory_usage = df.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    print('Starting memory usage is {:5.5f}'.format(start_memory_usage))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in types: \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            for n_key, n_value in numerics.items(): \n",
    "                if c_min > n_value[0] and c_max < n_value[1]:\n",
    "                    df[col] = df[col].astype(n_key)\n",
    "                    break\n",
    "    \n",
    "    end_memory_usage = df.memory_usage(deep=True).sum() / (1024**2)\n",
    "    if verbose: \n",
    "        print('Memory usage decreased to {:5.5f} Mb ({:.5f}% reduction)'.format(end_memory_usage, 100 * (start_memory_usage - end_memory_usage) / start_memory_usage))\n",
    "    print('------------------------------------------------------------------')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9787ef6-d784-4e19-ba4e-402b198477c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHRMetsDataset():\n",
    "    ## Merge cleaned dataframes\n",
    "    \n",
    "    # read the heartrate and mets dataframe\n",
    "    raw_data_path = f'{os.getcwd()}/data_raw/RAW-Fitabase Data 4.12.16-5.12.16/'\n",
    "    df_mets = pd.read_csv(raw_data_path+'minuteMETsNarrow_merged.csv')\n",
    "    df_heartrate = pd.read_csv(raw_data_path+'heartrate_seconds_merged.csv')\n",
    "    \n",
    "    # update columns names to be the same\n",
    "    df_mets.columns = ['id', 'timestamp', 'mets']\n",
    "    df_heartrate.columns = ['id', 'timestamp', 'bpm']\n",
    "        \n",
    "    # clean dataframes and reduce memory usage\n",
    "    df_mets = filterDataset(df_mets)\n",
    "    df_mets = reduceMemoryUsage(df_mets)\n",
    "    df_mets = parseDateTime(df_mets)\n",
    "    df_heartrate = filterDataset(df_heartrate)\n",
    "    df_heartrate = reduceMemoryUsage(df_heartrate)\n",
    "    df_heartrate = parseDateTime(df_heartrate)\n",
    "    \n",
    "    # merge dataframes using the column names and with an inner join\n",
    "    df_merged_inner = pd.merge(df_mets, df_heartrate, on=['id', 'date', 'time'], how='inner')\n",
    "    df_merged_right = pd.merge(df_mets, df_heartrate, on=['id', 'date', 'time'], how='right')\n",
    "    interim_data_path = f'{os.getcwd()}/data_interim/'\n",
    "    df_merged_inner.to_csv(f'{interim_data_path}heartrate_mets_merged_inner.csv', index=False)\n",
    "    df_merged_right.to_csv(f'{interim_data_path}heartrate_mets_merged_right.csv', index=False)\n",
    "    \n",
    "    # create heartrate dataset of cleaned results\n",
    "    df_heartrate.to_csv(f'{interim_data_path}heartrate_fiveseconds_intervals.csv', index=False)\n",
    "   \n",
    "    print('Heartrate and METS dataframes are merged')\n",
    "    df_merged_inner[:3]\n",
    "    df_merged_right[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d87cf5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter Dataset\n",
      "           id              timestamp  mets\n",
      "0  1503960366  4/12/2016 12:00:00 AM    10\n",
      "1  1503960366  4/12/2016 12:01:00 AM    10\n",
      "2  1503960366  4/12/2016 12:02:00 AM    10\n",
      "3  1503960366  4/12/2016 12:03:00 AM    10\n",
      "4  1503960366  4/12/2016 12:04:00 AM    10\n",
      "Column Names: id            int64\n",
      "timestamp    object\n",
      "mets          int64\n",
      "dtype: object\n",
      "The sum of null values are: id           0\n",
      "timestamp    0\n",
      "mets         0\n",
      "dtype: int64\n",
      "Count of cells BEFORE dropping null: 3976740 \n",
      "\n",
      "Count of cells AFTER dropping null: 3976740 \n",
      "\n",
      "------------------------------------------------------------------\n",
      "Reduce Memory\n",
      "Starting memory usage is 117.53323\n",
      "Memory usage decreased to 109.94820 Mb (6.45352% reduction)\n",
      "------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "Filter Dataset\n",
      "           id             timestamp  bpm\n",
      "0  2022484408  4/12/2016 7:21:00 AM   97\n",
      "1  2022484408  4/12/2016 7:21:05 AM  102\n",
      "2  2022484408  4/12/2016 7:21:10 AM  105\n",
      "3  2022484408  4/12/2016 7:21:20 AM  103\n",
      "4  2022484408  4/12/2016 7:21:25 AM  101\n",
      "Column Names: id            int64\n",
      "timestamp    object\n",
      "bpm           int64\n",
      "dtype: object\n",
      "The sum of null values are: id           0\n",
      "timestamp    0\n",
      "bpm          0\n",
      "dtype: int64\n",
      "Count of cells BEFORE dropping null: 7450974 \n",
      "\n",
      "Count of cells AFTER dropping null: 7450974 \n",
      "\n",
      "------------------------------------------------------------------\n",
      "Reduce Memory\n",
      "Starting memory usage is 220.17280\n",
      "Memory usage decreased to 205.96120 Mb (6.45475% reduction)\n",
      "------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "Heartrate and METS dataframes are merged\n"
     ]
    }
   ],
   "source": [
    "## create the heartrate_mets_merged.csv file with processed data\n",
    "createHRMetsDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a0367",
   "metadata": {},
   "source": [
    "Step 2: Create ManualInput Dataset\n",
    "Columns = blood pressure, weight, calorie consumption, symptoms, mental health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0feaf42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateManualInput():\n",
    "    # schema = {\n",
    "    # 'blood_pressure': 'gaussian_kde',\n",
    "    # 'glucose': 'beta',\n",
    "    # 'weight': 'bounded',\n",
    "    # 'calorie_consumption': 'poisson',\n",
    "    # 'symptoms_code': 'categorical',\n",
    "    # 'mental_health_code': 'categorical' \n",
    "    # }\n",
    "\n",
    "    # create layout of dataset (this is daily manual input april 12 - may 12 2016)\n",
    "    # collect all the id numbers display each for each day\n",
    "    print('Complete Tomorrow')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bebb20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Tomorrow\n"
     ]
    }
   ],
   "source": [
    "generateManualInput()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc439b1f",
   "metadata": {},
   "source": [
    "Step 3: Sleep & Actvity Tracking Dataset Cleaning (Select the most important attributes and convert each dataset into interim ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a626bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processContextualDatasets():\n",
    "    raw_data_path = f'{os.getcwd()}/data_raw/RAW-Fitabase Data 4.12.16-5.12.16/'\n",
    "    \n",
    "    ## Cleaning SleepDay Dataset\n",
    "    df_sleepDay = pd.read_csv(raw_data_path+'sleepDay_merged.csv')\n",
    "    df_sleepDay.columns = ['id', 'timestamp', 'total_sleep_records', 'total_minutes_asleep', 'total_time_inbed']\n",
    "    df_sleepDay.drop(columns=['total_time_inbed'], inplace=True)\n",
    "    \n",
    "    df_sleepDay = filterDataset(df_sleepDay)\n",
    "    df_sleepDay = reduceMemoryUsage(df_sleepDay)\n",
    "    df_sleepDay = parseDateTime(df_sleepDay)\n",
    "    df_sleepDay.drop(columns=['time'], inplace=True)\n",
    "    \n",
    "    # Write Dataset to csv \n",
    "    interim_data_path = f'{os.getcwd()}/data_interim/'\n",
    "    df_sleepDay.to_csv(f'{interim_data_path}daily_sleep.csv', index=False)\n",
    "    \n",
    "    ## Cleaning Activity Dataset\n",
    "    df_dailyActivity = pd.read_csv(f'{raw_data_path}dailyActivity_merged.csv')\n",
    "    df_dailyActivity = df_dailyActivity.iloc[:,[0,1,2,3,10,11,12,13,14]]\n",
    "    df_dailyActivity.columns = ['id', 'date', 'total_steps', 'total_distance_miles', 'very_active_minutes', 'fairly_active_minutes', 'lightly_active_minutes', 'sedentary_minutes', 'calories']\n",
    "\n",
    "    df_dailyActivity = filterDataset(df_dailyActivity)\n",
    "    df_dailyActivity = reduceMemoryUsage(df_dailyActivity)\n",
    "    \n",
    "    # merge sleep day and activity day\n",
    "    df_merged = pd.merge(df_sleepDay, df_dailyActivity, on=['id', 'date'], how='inner')\n",
    "    df_merged.to_csv(f'{interim_data_path}daily_sleep_activity.csv', index=False)\n",
    "    \n",
    "    print('Daily Activity and Sleep is Merged')\n",
    "    df_merged[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d181f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter Dataset\n",
      "           id              timestamp  total_sleep_records  \\\n",
      "0  1503960366  4/12/2016 12:00:00 AM                    1   \n",
      "1  1503960366  4/13/2016 12:00:00 AM                    2   \n",
      "2  1503960366  4/15/2016 12:00:00 AM                    1   \n",
      "3  1503960366  4/16/2016 12:00:00 AM                    2   \n",
      "4  1503960366  4/17/2016 12:00:00 AM                    1   \n",
      "\n",
      "   total_minutes_asleep  \n",
      "0                   327  \n",
      "1                   384  \n",
      "2                   412  \n",
      "3                   340  \n",
      "4                   700  \n",
      "Column Names: id                       int64\n",
      "timestamp               object\n",
      "total_sleep_records      int64\n",
      "total_minutes_asleep     int64\n",
      "dtype: object\n",
      "The sum of null values are: id                      0\n",
      "timestamp               0\n",
      "total_sleep_records     0\n",
      "total_minutes_asleep    0\n",
      "dtype: int64\n",
      "Count of cells BEFORE dropping null: 1652 \n",
      "\n",
      "Count of cells AFTER dropping null: 1652 \n",
      "\n",
      "------------------------------------------------------------------\n",
      "Reduce Memory\n",
      "Starting memory usage is 0.04018\n",
      "Memory usage decreased to 0.03506 Mb (12.74177% reduction)\n",
      "------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "Filter Dataset\n",
      "           id       date  total_steps  total_distance_miles  \\\n",
      "0  1503960366  4/12/2016        13162                  8.50   \n",
      "1  1503960366  4/13/2016        10735                  6.97   \n",
      "2  1503960366  4/14/2016        10460                  6.74   \n",
      "3  1503960366  4/15/2016         9762                  6.28   \n",
      "4  1503960366  4/16/2016        12669                  8.16   \n",
      "\n",
      "   very_active_minutes  fairly_active_minutes  lightly_active_minutes  \\\n",
      "0                   25                     13                     328   \n",
      "1                   21                     19                     217   \n",
      "2                   30                     11                     181   \n",
      "3                   29                     34                     209   \n",
      "4                   36                     10                     221   \n",
      "\n",
      "   sedentary_minutes  calories  \n",
      "0                728      1985  \n",
      "1                776      1797  \n",
      "2               1218      1776  \n",
      "3                726      1745  \n",
      "4                773      1863  \n",
      "Column Names: id                          int64\n",
      "date                       object\n",
      "total_steps                 int64\n",
      "total_distance_miles      float64\n",
      "very_active_minutes         int64\n",
      "fairly_active_minutes       int64\n",
      "lightly_active_minutes      int64\n",
      "sedentary_minutes           int64\n",
      "calories                    int64\n",
      "dtype: object\n",
      "The sum of null values are: id                        0\n",
      "date                      0\n",
      "total_steps               0\n",
      "total_distance_miles      0\n",
      "very_active_minutes       0\n",
      "fairly_active_minutes     0\n",
      "lightly_active_minutes    0\n",
      "sedentary_minutes         0\n",
      "calories                  0\n",
      "dtype: int64\n",
      "Count of cells BEFORE dropping null: 8460 \n",
      "\n",
      "Count of cells AFTER dropping null: 8460 \n",
      "\n",
      "------------------------------------------------------------------\n",
      "Reduce Memory\n",
      "Starting memory usage is 0.11642\n",
      "Memory usage decreased to 0.07966 Mb (31.57205% reduction)\n",
      "------------------------------------------------------------------\n",
      "Daily Activity and Sleep is Merged\n"
     ]
    }
   ],
   "source": [
    "processContextualDatasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
